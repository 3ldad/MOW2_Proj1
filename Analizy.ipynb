{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba330830458151b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Wstępna Analiza Danych - MOW 2\n",
    "### 2016 UK Road Safety: Traffic Accidents and Vehicles\n",
    "\n",
    "Anastazja Kandratsiuk, Bartosz Bojarski\n",
    "\n",
    "Opis zbioru:\n",
    "Zbiór danych zawiera informacje o wszystkich wypadkach drogowych w Wielkiej Brytani z roku 2016. Dane zostały przygotowane przez Departament Transportu Wielkiej Brytanii i przez inicjatywę Open Gov. Oryginalne dane są podzielone na cztery pliki, które opisują parametry dotyczące ofiar, pojazdów, czy okoliczności wypadków. Zostały one połączone w dwa zbiory danych, jeden opisujący geolokację wypadków, a drugi zawierający wszystkie pozostałe informacje.  \n",
    "Część kolumn jest przygotowana w formie kodów, które wymagają przetłumaczenia na zrozumiałe wartości. Będzie to robione przy pomocy słowników, które zostały dostarczone wraz z danymi, a sama translacja będzie wykonywana w trakcie analizy danych.\n",
    "\n",
    "\n",
    "\n",
    "Import bibliotek"
   ]
  },
  {
   "cell_type": "code",
   "id": "c00315bc6a415872",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "\n",
    "from shapely.geometry import Point\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "620f804aa873a706",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c7b405a56ba48cc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Casualties = pd.read_csv('dane/Cas.csv')\n",
    "MakeModel = pd.read_csv('dane/MakeModel2016.csv')\n",
    "Accidents = pd.read_csv('dane/dftRoadSafety_Accidents_2016.csv', low_memory=False)\n",
    "Vehicles = pd.read_csv('dane/Veh.csv')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7137c49feb714de4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rozbicie danych na dane geograficzne i pozostałe"
   ]
  },
  {
   "cell_type": "code",
   "id": "d0a50bfc0a55397a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Comp_data = pd.merge(Accidents, Casualties, on='Accident_Index')\n",
    "Comp_data = pd.merge(Comp_data, Vehicles, on='Accident_Index')\n",
    "Comp_data = pd.merge(Comp_data, MakeModel, on='Accident_Index')\n",
    "\n",
    "Geo_data = pd.DataFrame(Comp_data, columns=['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'Latitude'])\n",
    "Data_no_geo = Comp_data.drop(['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'Latitude'], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "840cd7763aa7c494",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Prezentacja podstawowych danych zbioru danych\n",
    "\n",
    "Zbiór danych posiada 92 kolumny i 804853 wiersze. Kluczem głównym dla zbioru danych jest kolumna 'Accident_Index'. \n",
    "Kolejne cztery kolumny zawierają informacje o geolokalizacji wypadków. Pozostałe kolumny zawierają informacje o wypadkach, ofiarach, pojazdach, czy okolicznościach wypadków."
   ]
  },
  {
   "cell_type": "code",
   "id": "a62bdf5951559cbd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Comp_data.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a65b8affc8cfd001",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data_no_geo.describe()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a7ad5812aa71458",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Sprawdzenie brakujących danych\n",
    "\n",
    "W zbiorze danych znajdują się brakujące dane w niektórych kolumnach. By spełnić wymagania projektu, będziemy dodawać brakujące dane w kolumnach, które będą analizowane, by osiągnąć poziom około 10% brakujących danych. W chwili obecnej najwięcej brakujących danych mamy w przypadku informacji o modelu auta (około 15% brakujących danych), a następnie informacje o jednostce geograficznej w której doszło do wypadku (około 5% brakujących danych). Jednak ta metoda sprawdzania wartości brakujących jest niewystarczająca, ponieważ w zakodowanych kolumnach wartość -1 oznacza brakujące dane."
   ]
  },
  {
   "cell_type": "code",
   "id": "df90939acd5dd6d6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "miss_data = Comp_data.isnull().sum()\n",
    "miss_data = miss_data[miss_data >= 1]\n",
    "print(\"Missing data that > 0:\")\n",
    "print(miss_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1bca16d48f7dc87c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Przykładowa analiza dla prędkości limitów"
   ]
  },
  {
   "cell_type": "code",
   "id": "7180495a1fa7762",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Histogram prędkości limitów\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(Comp_data['Speed_limit'], bins=20, kde=True)\n",
    "plt.title('Distribution of speed limits')\n",
    "plt.xlabel('Speed limit')\n",
    "plt.ylabel('Number of accidents')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fb16cb5a82f1d01d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Dodanie wykresu histogramu i pudełkowego dla prędkości limitów umożliwia nam lepsze zrozumienie rozkładu prędkości w danych dotyczących wypadków drogowych. Histogram prezentuje nam dystrybucję prędkości limitów na drogach, co pozwala zobaczyć, w jakich przedziałach prędkości występuje najwięcej wypadków (z wykresu wyżej widać że jest to 30 mil na godzinę).  Z kolei wykres pudełkowy pozwala nam zidentyfikować wartości odstające oraz zakres prędkości, w którym znajduje się większość obserwacji. "
   ]
  },
  {
   "cell_type": "code",
   "id": "b4110da3d9189f36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Wykres pudełkowy prędkości limitów\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x=Comp_data['Speed_limit'])\n",
    "plt.title('Boxplot of speed limits')\n",
    "plt.xlabel('Speed limit')\n",
    "plt.show()\n",
    "\n",
    "# Statystyki opisowe prędkości limitów\n",
    "print(\"Descriptive statistics for speed limits:\")\n",
    "print(Comp_data['Speed_limit'].describe())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bc0d5329b8a2ce19",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na podstawie danych dotyczących prędkości limitów można wywnioskować:\n",
    "1. Średnia prędkość limitu wynosi około 41.79 mil na godzinę.\n",
    "2. Odchylenie standardowe wynoszące około 15.80 sugeruje, że rozrzut prędkości limitów między wypadkami był stosunkowo niewielki w porównaniu do średniej wartości.\n",
    "3. Wartości kwartyla 25% i 50% są identyczne i wynoszą 30 mil na godzinę, co oznacza, że większość wypadków miała miejsce na obszarach o niższej prędkości limitu.\n",
    "4. Wartość maksymalna prędkości limitu wynosi 70 mil na godzinę. Występowanie przypadków wypadków na obszarach o wyższych prędkościach limitów może wskazywać na potencjalnie większe ryzyko dla bezpieczeństwa drogowego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34331eb2113d653",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Analiza prędkości limitów według marki auta"
   ]
  },
  {
   "cell_type": "code",
   "id": "cac6c982dec21265",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "missing_data_make = Comp_data.groupby('make')['Speed_limit'].apply(lambda x: x.isnull().sum())\n",
    "missing_data_make = missing_data_make[missing_data_make != 0]\n",
    "print(missing_data_make)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "79a8b2fc34cba2c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "missing_data_make.plot(kind='bar')\n",
    "plt.title('Number of Missing Speed Limits by Make')\n",
    "plt.xlabel('Make')\n",
    "plt.ylabel('Number of Missing Values')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9f2a4d6e546e9581",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Analiza danych brakujących dotyczących prędkości pojazdów dla różnych marek samochodów pokazuje, że marka FORD, VAUXHALL, AUDI oraz Volkswagen są szczególnie narażone na braki danych. To może sugerować, że dla tych konkretnych marek istnieje większe ryzyko braku rejestracji prędkości pojazdów w przypadku wypadków drogowych. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fd56c9de3d0a6c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Histogramy\n",
    "\n",
    "Poniżej zaprezentowane są histogramy dla wybranych kolumn. Zaprezentowanie wszystkich histogramów w ramach jednego polecenia uniemożliwia wygodne odczytanie wartości z histogramów. Część z kolumn jest też zakodowana, więc nie ma sensu prezentować ich histogramów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f9e5105a3958f1",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "id": "fcb7e906244fac2c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "hist_subset = pd.DataFrame(Data_no_geo, columns=['Number_of_Vehicles', 'Number_of_Casualties', 'Road_Type', 'Speed_limit', 'Age_of_Driver', 'Age_of_Casualty', 'Day_of_Week'])\n",
    "hist = hist_subset.hist(bins=25, figsize=(20,15))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1dc71580012ca354",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Jak widać z powyższych wyreksów, większość wypadków drogowych w Wielkiej Brytanii odbywa się przy ograniczeniu prędkości do 30 mil na godzinę. Najwięcej wypadków drogowych ma miejsce w sobotę i piątek, a najmniej w poniedziałek. Największy odsetek kierowców powodujących wypadki to osoby w wieku 25-35 lat, choć dla ponad 10% wypadków wiek kierowcy nie jest znany. Analogicznie, najwięcej ofiar wypadków to osoby w wieku 25-35 lat. Można też wyczytać, że na większość wypadków drogowych przypada do 1 lub 2 pojazdy, a liczba ofiar wypadków zazwyczaj nie przekracza 5. Dodatkowo, najwięcej kolizji na drodze ma miejsce na drogach dwukierunkowych, jednopasmowych."
   ]
  },
  {
   "cell_type": "code",
   "id": "8d2e58b50dc64e24",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "box = Data_no_geo.boxplot(figsize=(20,15))\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2e058882cfc2b43",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Powyższy wykres pudełkowy pokazuje nam rozkład i rozproszenie danych dla poszczególnych cech. Można zauważyć wartości odstające dla następujących cech: 1st Road Number, 2nd Road Number, Vehicle Propulsion Code, Engine Capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c169746fd180a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wykresy typu Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "id": "b14a56be4a95d47a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Casualties_uniform = Casualties.drop(['Vehicle_Reference', 'Casualty_Reference', 'Age_of_Casualty', 'Casualty_Type' ], axis=1)\n",
    "Casualties_uniform.boxplot(figsize=(20,15))\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.title('Distribution of features on road accident casualties')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8017b93678e7e4bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rozpatrując wiek ofiar wypadków (Age_of_Casualty) można zauważyć, że mediana jest około połowy zakresu międzykwartylowego, z niektórymi wartościami odstającymi w górnej części zakresu. Dla klasy wypadków (Casualty_Class) można podkreślić, że większość danych koncentruje się w dolnej części zakresu międzykwartylowego, z niewielkim rozproszeniem i brakiem wartości odstających. Płeć ofiary wypadków (Sex_of_Casualty) może sugerować nam o niewielkiej różnice między mężczyznami a kobietami w kontekście wypadków drogowych, z podobnymi medianami dla obu grup. Na wykresie są widoczne dane odstające dla większości cech w tym dane brakujące oznaczone jako -1 za wyjątkiem klasy wypadków (Casualty_Class) oraz Casualty_IMD_Decile. "
   ]
  },
  {
   "cell_type": "code",
   "id": "87981d097d804320",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Vehicles_uniform = Vehicles.drop(['Engine_Capacity_(CC)'], axis=1)\n",
    "Vehicles_uniform.boxplot(figsize=(20,15))\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.title('Distribution of accident vehicle features')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f60f116f9fef90fe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rozpatrując wiek pojazdu (Age_of_Vehicle) może się wydawać że rozproszenie danych jest głównie w niższym wieku pojazdów, co sugeruje, że większość pojazdów wypadkowych jest stosunkowo młoda. Warto zwrócić uwagę na cechę 'Was_Vehicle_Left_Hand_Drive', gdzie większość danych jest skoncentrowana w określonej kategorii, co może wskazywać na przewagę określonego typu układu kierowniczego. Dla 'Vehicle_Type' można zauważyć znaczną różnorodność w rozproszeniu danych, co sugeruje, że wypadki dotykają różnych typów pojazdów w różnym stopniu. Cecha 'Towing_and_Articulation' wydaje się mieć niewielkie rozproszenie, co sugeruje, że większość danych koncentruje się wokół określonej kategorii lub kategorii. Na wykresie są widoczne dane odstające dla większości cech w tym dane brakujące oznaczone jako -1 za wyjątkiem Vehicle_Manoeuvre, Junction_Location, 1st_Point_of_Impact, Journey_Purpose_of_Driver, Driver_IMD_Decile oraz Vehicle_IMD_Decile."
   ]
  },
  {
   "cell_type": "code",
   "id": "a3e2c9e36241fde5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "MakeModel_uniform = MakeModel.drop(['accyr', 'Engine_Capacity_(CC)'], axis=1)\n",
    "MakeModel_uniform.boxplot(figsize=(20,15))\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.title('Distribution of features about make model')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b645343ce8a55c41",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Rozkład wieku pojazdów (Age_of_Vehicle) jest skoncentrowany w okolicach średniej wartości, co sugeruje, że większość pojazdów ma przeciętny wiek. Wartości Engine_Capacity_(CC) są rozproszone na całym zakresie, co wskazuje na różnorodność pojemności silnika w badanych pojazdach. Istnieje zauważalne rozproszenie wartości w różnych grupach wiekowych kierowców (Age_Band_of_Driver_y), co sugeruje, że wypadki występują w różnych grupach wiekowych. Na wykresie są widoczne dane odstające dla większości cech w tym dane brakujące oznaczone jako -1 za wyjątkiem Vehicle_Manoeuvre, Junction_Location, 1st_Point_of_Impact, Journey_Purpose_of_Driver, Driver_IMD_Decile oraz Vehicle_IMD_Decile."
   ]
  },
  {
   "cell_type": "code",
   "id": "6b125c6d3b70be18",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Accidents_uniform = Accidents.drop(['Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'Latitude', '1st_Road_Number', '2nd_Road_Number', 'Local_Authority_(District)', 'Police_Force'], axis=1)\n",
    "Accidents_uniform.boxplot(figsize=(20,15))\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.title('Distribution of features on road accidents')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "13a32e45e1765655",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Widać, że większość wypadków miała niski poziom powagi (Accident_Severity), z czego można wywnioskować, że większość wypadków drogowych nie prowadziła do poważnych konsekwencji. Rozkład liczby pojazdów biorących udział w wypadkach (Number_of_Vehicles) jest skoncentrowany wokół niższych wartości, ale istnieją również pojedyncze przypadki z dużą liczbą pojazdów, co może wskazywać na zróżnicowanie sytuacji wypadków. Widać rozproszenie wartości liczby ofiar (Number_of_Casualties), co sugeruje, że wypadki mogą mieć różne skutki w postaci rannych lub zabitych osób."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aae3ef3091e9d6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wykresy dotyczące groźności wypadków\n",
    "\n",
    "Zależność między liczbą ofiary wypadków, a ich groźnością jest jednym z najważniejszych parametrów analizy wypadków komunikacyjnych. Kluczowe jest zidentyfikowanie w jakich wypadkach dochodzi do najgroźniejszych obrażeń i pozwoli to na dalszą analizę pod kątem przyczyn takich zjawisk. Można dzięki nim wyodrębnić obszary, które wymagają poprawy, oraz zabezpieczyć tereny, które stawały się czarnymi punktami na mapach drogowych.\n",
    "Poniżej przedstawione są histogramy liczności wypadków o konkrentym stopniu szkodliwości, oraz wykresy pudełkowe, prezentujące wyżej opisaną zależność. Takie wykresy mogą służyć jako wstęp do dalszej selekcji danych, które będą analizowane pod kątem przyczyn wypadków, oraz do lepszego podzielenia danych na zbiory testowe i treningowe."
   ]
  },
  {
   "cell_type": "code",
   "id": "c83e59e3e36cc74a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tworzenie opisów do legendy\n",
    "Severity_legend = {\n",
    "    1: 'Fatal',\n",
    "    2: 'Serious',\n",
    "    3: 'Slight'\n",
    "}\n",
    "\n",
    "# Podstawienie opisów do wartości\n",
    "Comp_data['Accident_Severity'] = Comp_data['Accident_Severity'].map(Severity_legend)\n",
    "\n",
    "sns.boxplot(x='Accident_Severity', y='Number_of_Casualties', data=Comp_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6b301520909f65bc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "countplt = sns.countplot(x='Accident_Severity', data=Comp_data)\n",
    "countplt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7834bdd8eaecb1a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wyodrębnienie kolumny dotyczącej powodu podróży kierowcy\n",
    "\n",
    "Lepsze zrozumienie powodów dla których kierowcy ruszają w drogę może pomóc zrozumieć np. dlaczego przekroczyli dozwolony limit prędkości, albo dlaczego wyprzedzali na podwójnej ciągłej."
   ]
  },
  {
   "cell_type": "code",
   "id": "bc6f7586290c0db2",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "journey_purpose_counts = Data_no_geo['Journey_Purpose_of_Driver_y'].value_counts()\n",
    "\n",
    "# Tworzenie opisów do legendy\n",
    "journey_purpose_legend = {\n",
    "    1: 'Journey as part of work',\n",
    "    2: 'Commuting to/from work',\n",
    "    3: 'Taking pupil to/from school',\n",
    "    4: 'Pupil riding to/from school',\n",
    "    5: 'Other',\n",
    "    6: 'Not known',\n",
    "    -1: 'Data missing or out of range'\n",
    "}\n",
    "\n",
    "# Podstawienie opisów do wartości\n",
    "journey_purpose_counts.index = journey_purpose_counts.index.map(journey_purpose_legend)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "patches, texts, autotexts = plt.pie(journey_purpose_counts, startangle=140, autopct='', labels=None)\n",
    "\n",
    "# Dodawanie ręcznie etykiet procentowych na zewnątrz koła\n",
    "percent = journey_purpose_counts / journey_purpose_counts.sum() * 100\n",
    "labels = [f'{label}\\n{percentage:.1f}%' for label, percentage in zip(journey_purpose_counts.index, percent)]\n",
    "plt.legend(patches, labels, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "plt.title('Journey Purpose of Drivers Involved in Accidents (UK, 2016)')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6e5348d28aebf8f7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Mapa wypadków drogowych w Wielkiej Brytanii"
   ]
  },
  {
   "cell_type": "code",
   "id": "e5e638dcdcc6cd2c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Utworzenie wykresu mapy\n",
    "plt.figure(figsize=(10, 8))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_extent([-8, 2, 49.5, 60], crs=ccrs.PlateCarree())  # Ustawienie granic na Wielką Brytanię\n",
    "\n",
    "# Dodanie warstwy granic kraju na różowo z wbudowanych danych\n",
    "ax.add_feature(cfeature.BORDERS.with_scale('10m'), linewidth=1.5, edgecolor='pink')\n",
    "\n",
    "# Dodanie warstwy granic Wielkiej Brytanii z wbudowanych danych\n",
    "ax.add_feature(cfeature.COASTLINE.with_scale('10m'), linewidth=1.5, edgecolor='gray')\n",
    "\n",
    "# Dodanie punktów reprezentujących wypadki drogowe\n",
    "ax.scatter(Comp_data['Longitude'], Comp_data['Latitude'], transform=ccrs.PlateCarree(), color='red', alpha=0.5, s=10)\n",
    "\n",
    "plt.title('Mapa wypadków drogowych w Wielkiej Brytanii')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e91c1c58d289d816",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Ten wykres przedstawia mapę Wielkiej Brytanii z zaznaczonymi punktami reprezentującymi wypadki drogowe. Granice kraju są oznaczone różową linią, natomiast wybrzeże jest oznaczone szarą linią. Czerwone punkty na mapie reprezentują lokalizacje wypadków drogowych, gdzie każdy punkt symbolizuje jeden wypadek. Przezroczystość punktów została dostosowana, aby ułatwić zidentyfikowanie obszarów o większej gęstości wypadków. Całość ma na celu zobrazowanie rozkładu wypadków drogowych w Wielkiej Brytanii na tle geograficznych cech kraju."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c792e27620ec75",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wykres wypadków drogowych według marek samochodów"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ab81e2e23833cca",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analiza liczby wypadków według marki pojazdu\n",
    "wypadki_marka_auta = Data_no_geo.groupby('make')['Accident_Index'].count().sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "wypadki_marka_auta.head(10).plot(kind='bar', color='skyblue')\n",
    "plt.title('Number of accidents by car brand (Top 10)')\n",
    "plt.xlabel('Car brand')\n",
    "plt.ylabel('Number of accidents')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "672e7fe201ac6118",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Marki FORD, VAUXHALL i VOLKSWAGEN zajmują czołowe miejsca pod względem liczby wypadków. Można wywnioskować, że pojazdy tych marek są częściej zaangażowane w wypadki drogowe niż pojazdy innych marek. Także to może sugerować, że pojazdy tych marek mogą być bardziej narażone na ryzyko wypadków lub że występujące w nich usterki lub błędy konstrukcyjne mogą przyczyniać się do większej liczby kolizji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07bdeacf5a834f9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wykres kołowy wypadków drogowych według płci "
   ]
  },
  {
   "cell_type": "code",
   "id": "176612a3b646cdcf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "wypadki_plec_legend = {\n",
    "    1: 'Male',\n",
    "    2: 'Female',\n",
    "    3: 'Unknown',\n",
    "    -1: 'Data missing'\n",
    "}\n",
    "\n",
    "# Analiza wypadków według płci\n",
    "wypadki_wedlug_plci = Data_no_geo.groupby('Sex_of_Driver_y')['Accident_Index'].count()\n",
    "\n",
    "wypadki_wedlug_plci.index = wypadki_wedlug_plci.index.map(wypadki_plec_legend)\n",
    "\n",
    "print(\"Liczba wypadków według płci:\")\n",
    "print(wypadki_wedlug_plci)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.pie(wypadki_wedlug_plci, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Share of road accidents by gender')\n",
    "plt.axis('equal') \n",
    "plt.legend(labels=wypadki_wedlug_plci.index, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bf80b8d356450b77",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na podstawie analizy liczby wypadków według płci można zauważyć, że większość wypadków drogowych (64.7%) dotyczy mężczyzn, podczas gdy udział kobiet w tych wypadkach wynosi 28.8%. Istnieje również kategoria o nieznanym lub nieokreślonym statusie płciowym, która stanowi 6.5% wszystkich wypadków. Ten wynik sugeruje, że mężczyźni są bardziej narażeni na wypadki drogowe niż kobiety. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb387f0ef5f105",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Wykres słupkowy wypadków drogowych według wieku kierowców"
   ]
  },
  {
   "cell_type": "code",
   "id": "6e9a8d18d4879ca8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Analiza wieku kierowców\n",
    "analiza_wieku = Data_no_geo['Age_Band_of_Driver_y'].value_counts().sort_index()\n",
    "\n",
    "etykiety = {\n",
    "    '1': '0-5',\n",
    "    '2': '6-10',\n",
    "    '3': '11-15',\n",
    "    '4': '16-20',\n",
    "    '5': '21-25',\n",
    "    '6': '26-35',\n",
    "    '7': '36-45',\n",
    "    '8': '46-55',\n",
    "    '9': '56-65',\n",
    "    '10': '66-75',\n",
    "    '11': 'Over 75',\n",
    "    '-1': 'Data missing'\n",
    "}\n",
    "\n",
    "\n",
    "# Tworzenie wykresu słupkowego z etykietami\n",
    "plt.figure(figsize=(10, 6))\n",
    "analiza_wieku.plot(kind='bar', color='skyblue')\n",
    "plt.title('Analysis of the age of drivers')\n",
    "plt.xlabel('Age group')\n",
    "plt.ylabel('Number of accidents')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xticks(analiza_wieku.index, [etykiety.get(str(x), 'Unknown') for x in analiza_wieku.index])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "aad1216fc5ecea3d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Te dane sugerują, że najczęściej w wypadkach drogowych uczestniczą osoby w wieku produkcyjnym. Trzy najbardziej narażone na wypadki grupy wiekowe to osoby w przedziałach wiekowych od 26 do 35 lat, od 36 do 45 lat oraz od 46 do 55 lat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6b3379225a97e1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pairplot z wybranymi danymi"
   ]
  },
  {
   "cell_type": "code",
   "id": "606461760b734825",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "data_to_plot = Comp_data[['Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit']]\n",
    "\n",
    "# Przeprowadzenie analizy pairplotów\n",
    "sns.pairplot(data_to_plot)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6445afc7f4ae8dea",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "W przypadku zmiennych Number_of_Vehicles i Number_of_Casualties, histogramy te sugerują, że większość wypadków ma niewielką liczbę pojazdów i ofiar. Natomiast histogram prędkości limitów sugeruje, że większość wypadków ma miejsce przy ograniczeniach prędkości na poziomie 30 lub 60 mil na godzinę. Wykresy punktowe pozwalają zauważyć potencjalne zależności między zmiennymi, takie jak np. tendencję wzrostową liczby ofiar wraz ze wzrostem liczby pojazdów. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60219025724c0118",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Skalowanie\n",
    "Pozwala na dostosowanie różnych cech w danych do podobnej skali, co ułatwia porównywanie ich i poprawia działanie algorytmów uczenia maszynowego."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b8a09e4bc62a5c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### MinMaxScaler\n",
    "Jedna z popularnych technik skalowania danych, która przekształca cechy w zakres wartości od 0 do 1. Wartość minimalna każdej cechy jest przesunięta do 0, a wartość maksymalna jest przesunięta do 1, zachowując proporcje wartości między nimi."
   ]
  },
  {
   "cell_type": "code",
   "id": "eafe8b4ac5162a32",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "features_to_scale = ['Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(Comp_data[features_to_scale])\n",
    "\n",
    "Comp_data_scaled = Comp_data.copy()\n",
    "Comp_data_scaled[features_to_scale] = scaled_features"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "aaa3337238874a51",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "n_features = len(features_to_scale)\n",
    "\n",
    "data_before_after_scal = np.zeros((2, n_features))\n",
    "\n",
    "for i, feature in enumerate(features_to_scale):\n",
    "    data_before_after_scal[0, i] = Comp_data[feature].mean()\n",
    "    data_before_after_scal[1, i] = Comp_data_scaled[feature].mean()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.35\n",
    "index = np.arange(n_features)\n",
    "\n",
    "plt.bar(index, data_before_after_scal[0], bar_width, label='Before Scaling', color='skyblue')\n",
    "plt.bar(index + bar_width, data_before_after_scal[1], bar_width, label='After Scaling', color='salmon')\n",
    "\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.title('Mean Values Before and After MinMax Scaling')\n",
    "plt.xticks(index + bar_width / 2, features_to_scale)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "89efa4c3ea046a56",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Powyższy wykres porównuje wymiary przed i po skalowaniu dla wybranych chech. Po skalowaniu jest widoczne, że wartości wahają się od 0 do 1. "
   ]
  },
  {
   "cell_type": "code",
   "id": "321a463eed42d973",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(Comp_data['Speed_limit'], 'bo', markersize=1, label='Before Scaling')\n",
    "plt.plot(Comp_data_scaled['Speed_limit'], 'ro', markersize=1, label='After Scaling')\n",
    "plt.title('Speed Limit Before and After MinMax Scaling')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Speed Limit')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(Comp_data['Number_of_Vehicles'], 'bo', markersize=1, label='Before Scaling')\n",
    "plt.plot(Comp_data_scaled['Number_of_Vehicles'], 'ro', markersize=1, label='After Scaling')\n",
    "plt.title('Number of Vehicles Before and After MinMax Scaling')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Number of Vehicles')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(Comp_data['Number_of_Casualties'], 'bo', markersize=1, label='Before Scaling')\n",
    "plt.plot(Comp_data_scaled['Number_of_Casualties'], 'ro', markersize=1, label='After Scaling')\n",
    "plt.title('Number of Casualties Before and After MinMax Scaling')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Number of Casualties')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e2932bdc4f737da3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na powyższych wykresach można wyraźnie zobaczyć, jak wartości mieszczą się w zakresie od 0 do 1 po skalowaniu i jak wyglądały przed skalowaniem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddb700fd93c3856",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### StandardScaler\n",
    "Inna popularna technika skalowania danych, która przekształca cechy tak, aby miały średnią równą 0 i odchylenie standardowe równą 1."
   ]
  },
  {
   "cell_type": "code",
   "id": "1d95cb6ef6a3b489",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "features_to_scale = ['Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit']\n",
    "\n",
    "scaler_st = StandardScaler()\n",
    "scaled_features_st = scaler_st.fit_transform(Comp_data[features_to_scale])\n",
    "\n",
    "Comp_data_scaled_st = Comp_data.copy()\n",
    "Comp_data_scaled_st[features_to_scale] = scaled_features_st"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7cd3543a70e18655",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "scaled_features_st"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dda969d63d792dbe",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(13, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(Comp_data['Speed_limit'], 'bo', markersize=1, label='Before Scaling')\n",
    "plt.plot(Comp_data_scaled_st['Speed_limit'], 'ro', markersize=1, label='After Scaling')\n",
    "plt.title('Speed Limit Before and After Standard Scaling')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Speed Limit')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(Comp_data['Number_of_Vehicles'], 'bo', markersize=1, label='Before Scaling')\n",
    "plt.plot(Comp_data_scaled_st['Number_of_Vehicles'], 'ro', markersize=1, label='After Scaling')\n",
    "plt.title('Number of Vehicles Before and After Standard Scaling')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Number of Vehicles')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(Comp_data['Number_of_Casualties'], 'bo', markersize=1, label='Before Scaling')\n",
    "plt.plot(Comp_data_scaled_st['Number_of_Casualties'], 'ro', markersize=1, label='After Scaling')\n",
    "plt.title('Number of Casualties Before and After Standard Scaling')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Number of Casualties')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "46a4e1ab7a44f6ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na wykresach przedstawiających dane przed i po skalowaniu standardowym można zauważyć, że po skalowaniu wartości cech mają średnią bliską zeru. Skalowanie standardowe umożliwia sprowadzenie wartości cech do wspólnego zakresu, co może poprawić wydajność algorytmów uczenia maszynowego, które są wrażliwe na różnice w skali cech. Dzięki temu można uniknąć przewagi jednej cechy nad innymi ze względu na jej większą skalę."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44650dd693ce2efb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Macierz korelacji\n",
    "Macierz korelacji przedstawiona na wykresie ciepła pokazuje, w jakim stopniu zmienne są skorelowane ze sobą. Im ciemniejszy kolor, tym większa korelacja. W analizie danych dotyczących pojazdów możemy zauważyć, że niektóre zmienne mają silną korelację dodatnią, co oznacza, że zmieniają się one w tym samym kierunku. Natomiast brak korelacji między niektórymi zmiennymi może wskazywać na ich niezależność od siebie w kontekście analizowanych danych. "
   ]
  },
  {
   "cell_type": "code",
   "id": "84aca845c309d47c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Veh_float = Vehicles.drop(['Accident_Index', 'Vehicle_Reference', 'Age_of_Driver', 'Engine_Capacity_(CC)', 'Age_of_Vehicle', '1st_Point_of_Impact', 'Vehicle_Location-Restricted_Lane', 'Junction_Location', 'Was_Vehicle_Left_Hand_Drive?'], axis=1)\n",
    "Vehicle_corr = Veh_float.corr().round(2)\n",
    "sns.heatmap(Vehicle_corr, annot=True, cmap='copper')\n",
    "plt.title('Correlation matrix of Vehicles data')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "9af162aed9b59faf",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na przykład zmienna \"Age_Band_of_Driver\" wydaje się być silnie skorelowana z \"Age_Band_of_Driver_y\", co może sugerować spójność w sposobie zbierania tych danych lub istnienie pewnych wzorców wiekowych wśród kierowców różnych marek samochodów. Korelację można znaleźć między "
   ]
  },
  {
   "cell_type": "code",
   "id": "d87a6237118a2cc5",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Cas_float = Casualties.drop(['Accident_Index', 'Vehicle_Reference', 'Casualty_Reference', 'Age_of_Casualty', 'Casualty_Type'], axis=1)\n",
    "Casualty_corr = Cas_float.corr().round(2)\n",
    "sns.heatmap(Casualty_corr, annot=True, cmap='copper')\n",
    "plt.title('Correlation matrix of Casualties data')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8898c1679207659e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na podstawie wykresu korelacji widzimy korelację dodatnią o wartości 0.83 między \"Pedestrian_Location\" a \"Pedestrian_Movement\" sugeruje, że lokalizacja pieszych w stosunku do drogi jest mocno związana z ich ruchem w momencie wypadku. Natomiast korelację między \"Casualty_Class\" a \"Pedestrian_Location\" o wartości 0.73 wskazuje na związek między klasą ofiary (np. pieszy, kierowca) a jej lokalizacją w momencie wypadku. Te wyniki sugerują, że miejsce i sposób poruszania się pieszych mogą mieć istotny wpływ na rodzaj obrażeń w wypadkach drogowych."
   ]
  },
  {
   "cell_type": "code",
   "id": "cc6eb5114eb49d16",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Acc_float = Accidents.drop(['Accident_Index', 'Location_Easting_OSGR', 'Location_Northing_OSGR', 'Longitude', 'Latitude', 'Local_Authority_(District)', 'Police_Force', 'Date', 'Time', 'Local_Authority_(Highway)', 'LSOA_of_Accident_Location','1st_Road_Number', '2nd_Road_Number', '1st_Road_Class', 'Day_of_Week', 'Road_Type', 'Pedestrian_Crossing-Human_Control', 'Light_Conditions'], axis=1)\n",
    "Accident_corr = Acc_float.corr().round(2)\n",
    "sns.heatmap(Accident_corr, annot=True, cmap='copper')\n",
    "plt.title('Correlation matrix of Accidents data')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce00face2f615172",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Na podstawie wykresu korelacji dla danych dotyczących wypadków drogowych widzimy kilka interesujących zależności. Na przykład, mamy silną korelację dodatnią 0.67 między prędkością limitu drogowego a rodzaj miejscowości, w której miał miejsce wypadek drogowy (Urban or Rural area) co może sugerować, że wypadki na obszarach miejskich lub wiejskich mogą różnić się ze względu na prędkość. Ponadto, korelacja między szczegółami skrzyżowania (junction_detail) a kontrolą skrzyżowania (junction_control) oraz 2nd_Road_Class sugeruje pewne wzajemne powiązania między tymi czynnikami, co może być istotne dla zrozumienia mechanizmu wypadków drogowych. Korelacja o wartości 0.69 między junction_detail a junction_control. Korelacja o wartości 0.72 między junction_detail a 2nd road class.Co do liczby ofiar (number_of_casualities) i liczby pojazdów (number_of_vihicles), to umiarkowana korelacja o wartości 0.25 sugeruje, że większa liczba pojazdów może prowadzić do większej liczby ofiar, co jest intuicyjne, ale potwierdza to analiza danych."
   ]
  },
  {
   "cell_type": "code",
   "id": "90a79e6f75aa0341",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "MakeModel_float = MakeModel.drop(['Accident_Index', 'accyr', 'model', 'make', 'Vehicle_Location-Restricted_Lane', 'Vehicle_Type', 'Junction_Location', '1st_Point_of_Impact', 'Was_Vehicle_Left_Hand_Drive', 'Towing_and_Articulation'], axis=1)\n",
    "MakeModel_corr = MakeModel_float.corr().round(2)\n",
    "sns.heatmap(MakeModel_corr, annot=True, cmap='copper')\n",
    "plt.title('Correlation matrix of MakeModel data')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "raw",
   "id": "efbf085b22bbda57",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Wysoka korelacja między \"Vehicle Leaving Carriageway\" a \"Hit Object in Carriageway\" o wysokości 0.51 sugeruje, że opuszczenie pojazdu z drogi może wpływać na rodzaj obiektu, z którym pojazd koliduje. Natomiast, korelacja między \"Age_Band_of_Driver\" a \"Age_of_Vehicle\" wynosząca 0.13 jest stosunkowo niska, co sugeruje niewielkie związki między wiekiem kierowcy a wiekiem pojazdu. Z kolei, korelacja między \"Age_Band_of_Driver\" a \"Driver_Home_Area_Type\" wynosząca 0.45 sugeruje pewne powiązania między wiekiem kierowcy a typem obszaru, w którym mieszka. Podobnie, korelacja między \"Age_Band_of_Driver\" a \"Driver_IMD_Decline\" wynosząca 0.33 wskazuje na pewne związki między wiekiem kierowcy a ich stopniem deprywacji społecznej."
   ]
  },
  {
   "cell_type": "code",
   "id": "a1044651274b6798",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Data_no_geo_float = Data_no_geo.drop(['Accident_Index', 'Number_of_Vehicles', 'Number_of_Casualties', 'Speed_limit', 'Age_of_Driver', 'Age_of_Casualty', 'Day_of_Week', 'Road_Type', 'Time', 'Date', 'Local_Authority_(District)', 'Police_Force', 'Date', 'Time', 'Local_Authority_(Highway)', 'LSOA_of_Accident_Location', 'make', 'model', 'accyr'], axis=1)\n",
    "Data_no_geo_corr = Data_no_geo_float.corr().round(2)\n",
    "sns.heatmap(Data_no_geo_corr, cmap='copper')\n",
    "plt.title('Correlation matrix of All datasets')\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b467269d0d86fe91",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Macierz korelacji wszystkich zestawów danych pozwala na zrozumienie wzajemnych związków między różnymi zmiennymi w danych. Poprzez analizę korelacji można odkryć, które zmienne są ze sobą powiązane i w jaki sposób. To z kolei może pomóc w identyfikacji kluczowych czynników wpływających na badane zjawiska oraz w wyborze odpowiednich zmiennych do dalszej analizy i modelowania."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d6ec288969e0f4",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Poniżej znajduje się macierz korelacji dla wybranych cech."
   ]
  },
  {
   "cell_type": "code",
   "id": "5f356c1553db0d43",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "selected_features = ['Number_of_Vehicles', 'Number_of_Casualties', 'Road_Type', 'Speed_limit', 'Age_of_Driver', 'Age_of_Casualty', 'Day_of_Week', 'Accident_Severity', 'Weather_Conditions', 'Light_Conditions', 'Road_Surface_Conditions', 'Urban_or_Rural_Area', 'Junction_Detail']\n",
    "features_subset = Data_no_geo[selected_features]\n",
    "features_subset_corr = features_subset.corr().round(2)\n",
    "sns.heatmap(features_subset_corr, annot=True, cmap='copper')\n",
    "plt.title('Correlation matrix of chosen features')\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "273d2b388f9698c8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Analiza korelacji między wybranymi cechami i zmienną \"Accident_Severity\" może pomóc zidentyfikować istotne zmienne dla modelu klasyfikacji. Na podstawie wyników:\n",
    "* Istnieje umiarkowana dodatnia korelacja między \"Number_of_Vehicles\" a \"Number_of_Casualties\" (0.32), co sugeruje, że wypadki z większą liczbą pojazdów mogą częściej powodować większą liczbę ofiar.\n",
    "* \"Speed_limit\" wykazuje umiarkowaną dodatnią korelację z \"Number_of_Vehicles\" (0.29) i \"Number_of_Casualties\" (0.22), co sugeruje, że większe limity prędkości mogą być związane z większą liczbą pojazdów i ofiar.\n",
    "* \"Age_of_Casualty\" ma silną ujemną korelację z \"Age_of_Driver\" (-0.33), co wskazuje na to, że starsi kierowcy mogą być bardziej narażeni na wypadki z udziałem starszych osób.\n",
    "* Korelacja między \"Weather_Conditions\" a \"Road_Type\" (0.01) jest niska, co sugeruje, że warunki pogodowe mogą mieć niewielki wpływ na rodzaj drogi, na której występują wypadki.\n",
    "* \"Light_Conditions\" wykazuje niewielką dodatnią korelację z \"Road_Surface_Conditions\" (0.17), co sugeruje, że gorsze warunki oświetleniowe mogą być powiązane z gorszym stanem nawierzchni drogi.\n",
    "\n",
    "\n",
    "Te obserwacje mogą być użyteczne podczas budowania modelu klasyfikacji, aby wybrać istotne cechy dla przewidywania powagi wypadków."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Część 2 - Trenowanie modelu\n",
    "\n",
    "### Podział danych na zbiory treningowe i testowe"
   ],
   "id": "c617ef4f9c076f99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train_test_split(X, y, test_size=0.2, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "\n",
    "    n_samples = len(X)\n",
    "    shuffled_indices = np.random.permutation(n_samples)\n",
    "\n",
    "    n_test = int(n_samples * test_size)\n",
    "\n",
    "    test_indices = shuffled_indices[:n_test]\n",
    "    train_indices = shuffled_indices[n_test:]\n",
    "\n",
    "    X_train = X[train_indices]\n",
    "    X_test = X[test_indices]\n",
    "    y_train = y[train_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    total_TP = total_TN = total_FP = total_FN = 0\n",
    "    unique_classes = np.unique(y_true)\n",
    "    \n",
    "    for class_label in unique_classes:\n",
    "        TP = np.sum((y_true == class_label) & (y_pred == class_label))\n",
    "        TN = np.sum((y_true != class_label) & (y_pred != class_label))\n",
    "        FP = np.sum((y_true != class_label) & (y_pred == class_label))\n",
    "        FN = np.sum((y_true == class_label) & (y_pred != class_label))\n",
    "        \n",
    "        total_TP += TP\n",
    "        total_TN += TN\n",
    "        total_FP += FP\n",
    "        total_FN += FN\n",
    "\n",
    "    accuracy = (total_TP + total_TN) / (total_TP + total_TN + total_FP + total_FN)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def score_f1(y_true, y_pred):\n",
    "    classes = set(y_true)\n",
    "    f1_scores = []\n",
    "    for c in classes:\n",
    "        TP = np.sum((y_true == c) & (y_pred == c))\n",
    "        FP = np.sum((y_true != c) & (y_pred == c))\n",
    "        FN = np.sum((y_true == c) & (y_pred != c))\n",
    "        precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "        recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "    return np.mean(f1_scores)\n",
    "\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    precisions = []\n",
    "    for c in classes:\n",
    "        TP = np.sum((y_true == c) & (y_pred == c))\n",
    "        FP = np.sum((y_true != c) & (y_pred == c))\n",
    "        precision = TP / (TP + FP) if TP + FP > 0 else 0\n",
    "        precisions.append(precision)\n",
    "    return np.mean(precisions)\n",
    "\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    classes = np.unique(y_true)\n",
    "    recalls = []\n",
    "    for c in classes:\n",
    "        TP = np.sum((y_true == c) & (y_pred == c))\n",
    "        FN = np.sum((y_true == c) & (y_pred != c))\n",
    "        recall = TP / (TP + FN) if TP + FN > 0 else 0\n",
    "        recalls.append(recall)\n",
    "    return np.mean(recalls)\n",
    "\n",
    "\n",
    "#Data_no_geo_clean = Data_no_geo\n",
    "# Data_no_geo_clean.fillna(Data_no_geo.mean(), inplace=True)\n",
    "\n",
    "#X_array = Data_no_geo_clean.drop('Accident_Severity', axis=1).values\n",
    "#y_array = Data_no_geo_clean['Accident_Severity'].values\n",
    "\n",
    "Sel_data = features_subset.copy()\n",
    "Sel_data.fillna(Sel_data.mean(), inplace=True)\n",
    "\n",
    "X_array = Sel_data.drop('Accident_Severity', axis=1).values\n",
    "y_array = Sel_data['Accident_Severity'].values\n",
    "\n",
    "X_train_data, X_test_data, y_train_data, y_test_data = train_test_split(X_array, y_array, test_size=0.2, random_state=42)"
   ],
   "id": "b6e689d4022d4c3b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return precision, recall, f1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "51d0b7d7510247ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Trening modelu klasyfikacji na sześć różnych metod \n",
    "\n",
    "#### Random Forest"
   ],
   "id": "b5d1eea337d93cd8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Start_rand = time.time()\n",
    "RandomForestClassifier_model = RandomForestClassifier(random_state=17)\n",
    "RandomForestClassifier_model.fit(X_train_data, y_train_data)\n",
    "RandomForestClassifier_predictions = RandomForestClassifier_model.predict(X_test_data)\n",
    "RandomForestClassifier_accuracy = accuracy(y_test_data, RandomForestClassifier_predictions)\n",
    "End_rand = time.time()\n",
    "\n",
    "RandomForestClassifier_precision = precision(y_test_data, RandomForestClassifier_predictions)\n",
    "RandomForestClassifier_recall = recall(y_test_data, RandomForestClassifier_predictions)\n",
    "RandomForestClassifier_score_f1 = score_f1(y_test_data, RandomForestClassifier_predictions)\n",
    "RandomForestClassifier_duration = End_rand - Start_rand\n",
    "\n",
    "print(f'Random Forest Classifier accuracy: {RandomForestClassifier_accuracy:.2f}')\n",
    "print(f'Random Forest Classifier precision: {RandomForestClassifier_precision:.2f}')\n",
    "print(f'Random Forest Classifier recall: {RandomForestClassifier_recall:.2f}')\n",
    "print(f'Random Forest Classifier f1_score: {RandomForestClassifier_score_f1:.2f}')\n",
    "print(f'Random Forest Classifier training time: {RandomForestClassifier_duration:.2f} seconds')"
   ],
   "id": "c03358c35bbb8d26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree"
   ],
   "id": "f3ba46d0732233d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Start_dec = time.time()\n",
    "DecisionTreeClassifier_model = DecisionTreeClassifier(random_state=17)\n",
    "DecisionTreeClassifier_model.fit(X_train_data, y_train_data)\n",
    "DecisionTreeClassifier_predictions = DecisionTreeClassifier_model.predict(X_test_data)\n",
    "DecisionTreeClassifier_accuracy = accuracy(y_test_data, DecisionTreeClassifier_predictions)\n",
    "End_dec = time.time()\n",
    "\n",
    "DecisionTreeClassifier_precision = precision(y_test_data, DecisionTreeClassifier_predictions)\n",
    "DecisionTreeClassifier_recall = recall(y_test_data, DecisionTreeClassifier_predictions)\n",
    "DecisionTreeClassifier_score_f1 = score_f1(y_test_data, DecisionTreeClassifier_predictions)\n",
    "DecisionTreeClassifier_duration = End_dec - Start_dec\n",
    "\n",
    "print(f'Decision Tree Classifier accuracy: {DecisionTreeClassifier_accuracy:.2f}')\n",
    "print(f'Decision Tree Classifier precision: {DecisionTreeClassifier_precision:.2f}')\n",
    "print(f'Decision Tree Classifier recall: {DecisionTreeClassifier_recall:.2f}')\n",
    "print(f'Decision Tree Classifier f1_score: {DecisionTreeClassifier_score_f1:.2f}')\n",
    "print(f'Decision Tree Classifier training time: {DecisionTreeClassifier_duration:.2f} seconds')"
   ],
   "id": "64935d0524ef9d6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### K-Nearest Neighbors"
   ],
   "id": "dee59a9504c0ed65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Start_knn = time.time()\n",
    "KNeighborsClassifier_model = KNeighborsClassifier()\n",
    "KNeighborsClassifier_model.fit(X_train_data, y_train_data)\n",
    "KNeighborsClassifier_predictions = KNeighborsClassifier_model.predict(X_test_data)\n",
    "KNeighborsClassifier_accuracy = accuracy(y_test_data, KNeighborsClassifier_predictions)\n",
    "End_knn = time.time()\n",
    "\n",
    "KNeighborsClassifier_precision = precision(y_test_data, KNeighborsClassifier_predictions)\n",
    "KNeighborsClassifier_recall = recall(y_test_data, KNeighborsClassifier_predictions)\n",
    "KNeighborsClassifier_score_f1 = score_f1(y_test_data, KNeighborsClassifier_predictions)\n",
    "KNeighborsClassifier_duration = End_knn - Start_knn\n",
    "\n",
    "print(f'K-Nearest Neighbors Classifier accuracy: {KNeighborsClassifier_accuracy:.2f}')\n",
    "print(f'K-Nearest Neighbors Classifier precision: {KNeighborsClassifier_precision:.2f}')\n",
    "print(f'K-Nearest Neighbors Classifier recall: {KNeighborsClassifier_recall:.2f}')\n",
    "print(f'K-Nearest Neighbors Classifier f1_score: {KNeighborsClassifier_score_f1:.2f}')\n",
    "print(f'K-Nearest Neighbors Classifier training time: {KNeighborsClassifier_duration:.2f} seconds')"
   ],
   "id": "4d1297356800cbb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### LGBM Classifier"
   ],
   "id": "d9e4f7d2a4e388c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Start_lgbm = time.time()\n",
    "LGBMClassifier_model = lgb.LGBMClassifier()\n",
    "LGBMClassifier_model.fit(X_train_data, y_train_data)\n",
    "LGBMClassifier_predictions = LGBMClassifier_model.predict(X_test_data)\n",
    "LGBMClassifier_accuracy = accuracy(y_test_data, LGBMClassifier_predictions)\n",
    "End_lgbm = time.time()\n",
    "\n",
    "LGBMClassifier_precision = precision(y_test_data, LGBMClassifier_predictions)\n",
    "LGBMClassifier_recall = recall(y_test_data, LGBMClassifier_predictions)\n",
    "LGBMClassifier_score_f1 = score_f1(y_test_data, LGBMClassifier_predictions)\n",
    "LGBMClassifier_duration = End_lgbm - Start_lgbm\n",
    "\n",
    "print(f'LGBM Classifier accuracy: {LGBMClassifier_accuracy:.2f}')\n",
    "print(f'LGBM Classifier precision: {LGBMClassifier_precision:.2f}')\n",
    "print(f'LGBM Classifier recall: {LGBMClassifier_recall:.2f}')\n",
    "print(f'LGBM Classifier f1_score: {LGBMClassifier_score_f1:.2f}')\n",
    "print(f'LGBM Classifier training time: {LGBMClassifier_duration:.2f} seconds')"
   ],
   "id": "2dbd50a77abf7607",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### XGBoost Classifier"
   ],
   "id": "a9096524833455e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Start_xgb = time.time()\n",
    "XGBClassifier_model = xgb.XGBClassifier()\n",
    "y_train_data_zero_based = y_train_data - 1\n",
    "XGBClassifier_model.fit(X_train_data, y_train_data_zero_based)\n",
    "XGBClassifier_predictions = XGBClassifier_model.predict(X_test_data)\n",
    "XGBClassifier_accuracy = accuracy(y_test_data, XGBClassifier_predictions)\n",
    "End_xgb = time.time()\n",
    "\n",
    "XGBClassifier_precision = precision(y_test_data, XGBClassifier_predictions)\n",
    "XGBClassifier_recall = recall(y_test_data, XGBClassifier_predictions)\n",
    "XGBClassifier_score_f1 = score_f1(y_test_data, XGBClassifier_predictions)\n",
    "XGBClassifier_duration = End_xgb - Start_xgb\n",
    "\n",
    "print(f'XGBoost Classifier accuracy: {XGBClassifier_accuracy:.2f}')\n",
    "print(f'XGBoost Classifier precision: {XGBClassifier_precision:.2f}')\n",
    "print(f'XGBoost Classifier recall: {XGBClassifier_recall:.2f}')\n",
    "print(f'XGBoost Classifier f1_score: {XGBClassifier_score_f1:.2f}')\n",
    "print(f'XGBoost Classifier training time: {XGBClassifier_duration:.2f} seconds')"
   ],
   "id": "3ba7c31ec28a5200",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### CatBoost Classifier"
   ],
   "id": "25e8430bbab6355a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Start_cb = time.time()\n",
    "CatBoostClassifier_model = cb.CatBoostClassifier(iterations=100)\n",
    "train_pool = cb.Pool(X_train_data, y_train_data)\n",
    "test_pool = cb.Pool(X_test_data, y_test_data)\n",
    "\n",
    "CatBoostClassifier_model.fit(train_pool, eval_set=test_pool)\n",
    "CatBoostClassifier_predictions = CatBoostClassifier_model.predict(X_test_data)\n",
    "CatBoostClassifier_accuracy = calculate_accuracy(y_test_data, CatBoostClassifier_predictions)\n",
    "End_cb = time.time()\n",
    "\n",
    "CatBoostClassifier_precision, CatBoostClassifier_recall, CatBoostClassifier_f1_score = calculate_metrics(y_test_data, CatBoostClassifier_predictions)\n",
    "CatBoostClassifier_duration = End_cb - Start_cb\n",
    "\n",
    "print(f'CatBoost Classifier accuracy: {CatBoostClassifier_accuracy:.2f}')\n",
    "print(f'CatBoost Classifier precision: {CatBoostClassifier_precision:.2f}')\n",
    "print(f'CatBoost Classifier recall: {CatBoostClassifier_recall:.2f}')\n",
    "print(f'CatBoost Classifier F1 score: {CatBoostClassifier_f1_score:.2f}')\n",
    "print(f'CatBoost Classifier training time: {CatBoostClassifier_duration:.2f} seconds')"
   ],
   "id": "5ccbac9c6f6e7206",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_hist_y_and_pred(y_test_data, y_test_pred, name_of_method):\n",
    "    class_counts_true = np.bincount(y_test_data)[1:] \n",
    "    class_counts_pred = np.bincount(y_test_pred)[1:]\n",
    "    num_classes = len(class_counts_true)\n",
    "\n",
    "    bar_width = 0.35\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(np.arange(1, num_classes + 1) - bar_width/2, class_counts_true, bar_width, color='skyblue',label='y_true')\n",
    "    plt.bar(np.arange(1, num_classes + 1) + bar_width/2, class_counts_pred, bar_width, color='orange', label='y_pred')\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Number of occurrences')\n",
    "    plt.title('Histogram of occurrences\\'s number of classes - ' + name_of_method)\n",
    "    plt.xticks(np.arange(1, num_classes + 1), labels=np.arange(1, num_classes + 1))\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a2a02e1d67c8f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def show_conf_matrix(y_test_data, y_test_pred, name_of_method):\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test_data, y_test_pred)\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix=confusion_matrix, display_labels=np.unique(y_test_data))\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm_display.plot(cmap=plt.cm.Blues, xticks_rotation='vertical', values_format='d')\n",
    "    plt.title('Confusion Matrix - ' + name_of_method)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "86e9b1a4124bf0e8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Macierz konfuzji"
   ],
   "id": "de6493489e88c3b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Models = [RandomForestClassifier_model, DecisionTreeClassifier_model, KNeighborsClassifier_model, LGBMClassifier_model, XGBClassifier_model, CatBoostClassifier_model]\n",
    "Model_names = ['Random Forest', 'Decision Tree', 'K-Nearest Neighbors', 'LGBM', 'XGBoost', 'CatBoost']\n",
    "\n",
    "def plot_conf_matrix(model, model_name):\n",
    "    predictions = model.predict(X_test_data)\n",
    "    conf_matrix = metrics.confusion_matrix(y_test_data, predictions)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='copper')\n",
    "    plt.title(f'Confusion Matrix for {model_name}')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ],
   "id": "39edfad75da89180",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "show_hist_y_and_pred(y_test_data, RandomForestClassifier_predictions, \"RandomForestClassifier\")\n",
    "\n",
    "show_hist_y_and_pred(y_test_data, DecisionTreeClassifier_predictions, \"DecisionTreeClassifier\")\n",
    "\n",
    "show_hist_y_and_pred(y_test_data, KNeighborsClassifier_predictions, \"KNeighborsClassifier\")\n",
    "\n",
    "show_hist_y_and_pred(y_test_data, LGBMClassifier_predictions, \"LGBMClassifier\")\n",
    "\n",
    "show_hist_y_and_pred(y_test_data, XGBClassifier_predictions + 1, \"XGBClassifier\")"
   ],
   "id": "ff951118ec66a98"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "show_conf_matrix(y_test_data, RandomForestClassifier_predictions, \"RandomForestClassifier\")\n",
    "show_conf_matrix(y_test_data, DecisionTreeClassifier_predictions, \"DecisionTreeClassifier\")\n",
    "show_conf_matrix(y_test_data, KNeighborsClassifier_predictions, \"KNeighborsClassifier\")\n",
    "show_conf_matrix(y_test_data, LGBMClassifier_predictions, \"LGBMClassifier\")\n",
    "show_conf_matrix(y_test_data, XGBClassifier_predictions + 1, \"XGBClassifier\")\n",
    "show_conf_matrix(y_test_data, CatBoostClassifier_predictions, \"CatBoostClassifier\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0f7ab5af8c52f60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'Training Time'])\n",
    "\n",
    "def add_result(model_name, accuracy_val, precision_val, recall_val, f1_score_val, training_time):\n",
    "    results_df.loc[len(results_df)] = [model_name, accuracy_val, precision_val, recall_val, f1_score_val, training_time]\n",
    "\n",
    "add_result('Random Forest', RandomForestClassifier_accuracy, RandomForestClassifier_precision, RandomForestClassifier_recall, RandomForestClassifier_score_f1, RandomForestClassifier_duration)\n",
    "add_result('Decision Tree', DecisionTreeClassifier_accuracy, DecisionTreeClassifier_precision, DecisionTreeClassifier_recall, DecisionTreeClassifier_score_f1, DecisionTreeClassifier_duration)\n",
    "add_result('KNN', KNeighborsClassifier_accuracy, KNeighborsClassifier_precision, KNeighborsClassifier_recall, KNeighborsClassifier_score_f1, KNeighborsClassifier_duration)\n",
    "add_result('LGBM', LGBMClassifier_accuracy, LGBMClassifier_precision, LGBMClassifier_recall, LGBMClassifier_score_f1, LGBMClassifier_duration)\n",
    "add_result('XGBoost', XGBClassifier_accuracy, XGBClassifier_precision, XGBClassifier_recall, XGBClassifier_score_f1, XGBClassifier_duration)\n",
    "add_result('CatBoost', CatBoostClassifier_accuracy, CatBoostClassifier_precision, CatBoostClassifier_recall, CatBoostClassifier_f1_score, CatBoostClassifier_duration)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cca3072c9fa0b16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ac6780f53ee51e39"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "\n",
    "styled_results_df = results_df.style.highlight_max(color='limegreen').highlight_min(color='tomato')\n",
    "\n",
    "with open('str.html','w') as f:\n",
    "    styled_results_df.to_html(f)\n",
    "\n",
    "filename = ' str.html'\n",
    "webbrowser.open_new_tab(filename)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a90ca5519028225f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Analizując wyniki różnych modeli klasyfikacyjnych, można stwierdzić, że Random Forest i Decision Tree osiągnęły najwyższą skuteczność w klasyfikacji. Random Forest uzyskał najwyższą dokładność, co sugeruje, że agregacja wielu drzew decyzyjnych przyniosła korzyści. Jednakże, pomimo prostoty, pojedyncze drzewo decyzyjne również wykazało się wysoką dokładnością, co może być atrakcyjne ze względu na mniejsze wymagania obliczeniowe. \n",
    "\n",
    "Modele oparte na gradient boosting, takie jak XGBoost i LGBM, wykazały mieszane wyniki. W szczególności, XGBoost wydaje się mieć problemy z precyzją i czułością, co sugeruje, że wymaga on bardziej zaawansowanej regularyzacji lub optymalizacji. CatBoost, podobnie jak inne metody oparte na boostingu, uzyskał dobre wyniki, ale nieco niższe niż Random Forest i Decision Tree. Jego czas trenowania jest relatywnie krótki, co może być atrakcyjne w sytuacji, gdy obciążenie obliczeniowe jest istotne. Niemniej jednak, jego dokładność, precyzja i czułość są na zadowalającym poziomie. \n",
    "\n",
    "Algorytm KNN, mimo swojej popularności, nie osiągnął zadowalających wyników w tym zadaniu. Jego dokładność, precyzja i czułość były znacznie niższe niż w przypadku Random Forest i Decision Tree, a czas trenowania był najdłuższy spośród wszystkich modeli. Może to sugerować, że dla tego zestawu danych metoda oparta na odległościach nie jest odpowiednia."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf3cedc5b20ebdfb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Uczenie zespołowe\n",
    "Voting classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d65f3e20e1cc900"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class VotingClassifier:\n",
    "    def __init__(self, classifiers):\n",
    "        self.classifiers = classifiers\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for clf in self.classifiers:\n",
    "            clf.fit(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([clf.predict(X) for clf in self.classifiers])\n",
    "        return np.apply_along_axis(lambda x: np.argmax(np.bincount(x)), axis=1, arr=predictions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be526cc2dbc51f3c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "GaussianNB_model = GaussianNB()\n",
    "LinearDiscriminantAnalysis_model = LinearDiscriminantAnalysis()\n",
    "QuadraticDiscriminantAnalysis_model = QuadraticDiscriminantAnalysis()\n",
    "LogisticRegression_model = LogisticRegression(multi_class='multinomial', random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28f44601c16f4c6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "voting_clf_5 = VotingClassifier(classifiers=[GaussianNB_model, LinearDiscriminantAnalysis_model, QuadraticDiscriminantAnalysis_model, KNeighborsClassifier_model, LogisticRegression_model])\n",
    "voting_clf_5.fit(X_train_data, y_train_data)\n",
    "\n",
    "y_pred_voting_5 = voting_clf_5.predict(X_test_data)\n",
    "accuracy_voting_5 = accuracy_score(y_test_data, y_pred_voting_5)\n",
    "end_time = time.time()\n",
    "voting_clf_5_time = end_time - start_time\n",
    "print(f'Dokładność modelu (Voting Classifier) - 5 classifiers: {accuracy_voting_5:.2f}')\n",
    "print(f'Dokładność modelu (Voting Classifier) - 5 classifiers: {voting_clf_5_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efa9244761bc892d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "voting_clf_4 = VotingClassifier(classifiers=[GaussianNB_model, LinearDiscriminantAnalysis_model, QuadraticDiscriminantAnalysis_model, KNeighborsClassifier_model])\n",
    "voting_clf_4.fit(X_train_data, y_train_data)\n",
    "\n",
    "y_pred_voting_4 = voting_clf_4.predict(X_test_data)\n",
    "accuracy_voting_4 = accuracy_score(y_test_data, y_pred_voting_4)\n",
    "end_time = time.time()\n",
    "voting_clf_4_time = end_time - start_time\n",
    "print(f'Dokładność modelu (Voting Classifier) - 4 classifiers: {accuracy_voting_4:.2f}')\n",
    "print(f'Dokładność modelu (Voting Classifier) - 4 classifiers: {voting_clf_4_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b117911d49c3aedc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "voting_clf_3 = VotingClassifier(classifiers=[GaussianNB_model, LinearDiscriminantAnalysis_model, QuadraticDiscriminantAnalysis_model])\n",
    "voting_clf_3.fit(X_train_data, y_train_data)\n",
    "\n",
    "y_pred_voting_3 = voting_clf_3.predict(X_test_data)\n",
    "accuracy_voting_3 = accuracy_score(y_test_data, y_pred_voting_3)\n",
    "end_time = time.time()\n",
    "voting_clf_3_time = end_time - start_time\n",
    "\n",
    "print(f'Dokładność modelu (Voting Classifier) - 3 classifiers: {accuracy_voting_3:.2f}')\n",
    "print(f'Dokładność modelu (Voting Classifier) - 3 classifiers: {voting_clf_3_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b95c039bd25660"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "voting_clf_2 = VotingClassifier(classifiers=[GaussianNB_model, LinearDiscriminantAnalysis_model])\n",
    "voting_clf_2.fit(X_train_data, y_train_data)\n",
    "\n",
    "y_pred_voting_2 = voting_clf_2.predict(X_test_data)\n",
    "accuracy_voting_2 = accuracy_score(y_test_data, y_pred_voting_2)\n",
    "end_time = time.time()\n",
    "voting_clf_2_time = end_time - start_time\n",
    "\n",
    "print(f'Dokładność modelu (Voting Classifier) - 2 classifiers: {accuracy_voting_2:.2f}')\n",
    "print(f'Dokładność modelu (Voting Classifier) - 2 classifiers: {voting_clf_2_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e9b5431a543386b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "eclf_2 = VotingClassifier(\n",
    "    estimators=[(\"ld\", LinearDiscriminantAnalysis_model), (\"gnb\", GaussianNB_model)],\n",
    "    voting=\"hard\",\n",
    "    weights=[1, 1],\n",
    ")\n",
    "\n",
    "eclf_2.fit(X_train_data, y_train_data)\n",
    "y_pred_eclf_2 = eclf_2.predict(X_test_data)\n",
    "accuracy_eclf_2 = accuracy_score(y_test_data, y_pred_eclf_2)\n",
    "end_time = time.time()\n",
    "eclf_2_time = end_time - start_time\n",
    "\n",
    "print(f'Dokładność modelu VotingClassifier hard (sklearn) - 2 classifiers: {accuracy_eclf_2:.2f}')\n",
    "print(f'VotingClassifier hard (sklearn) - 2 classifiers, training time: {eclf_2_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de89dc8424f5756c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "start_time = time.time()\n",
    "eclf_5 = VotingClassifier(\n",
    "    estimators=[(\"ld\", LinearDiscriminantAnalysis_model), (\"gnb\", GaussianNB_model), (\"qd\", QuadraticDiscriminantAnalysis_model), (\"KNC\", KNeighborsClassifier_model), (\"lr\", LogisticRegression_model)],\n",
    "    voting=\"hard\",\n",
    "    weights=[1, 1, 1, 1, 1],\n",
    ")\n",
    "\n",
    "eclf_5.fit(X_train_data, y_train_data)\n",
    "y_pred_eclf_5 = eclf_5.predict(X_test_data)\n",
    "accuracy_eclf_5 = accuracy_score(y_test_data, y_pred_eclf_5)\n",
    "end_time = time.time()\n",
    "eclf_5_time = end_time - start_time\n",
    "\n",
    "print(f'Dokładność modelu VotingClassifier hard (sklearn) - 5 classifiers: {accuracy_eclf_5:.2f}')\n",
    "print(f'VotingClassifier hard (sklearn) - 5 classifiers, training time: {eclf_5_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a731c68bd265bb85"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Stacking classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d846d7eec7fdef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class StackingClassifier:\n",
    "    def __init__(self, base_classifiers, meta_classifier):\n",
    "        self.base_classifiers = base_classifiers\n",
    "        self.meta_classifier = meta_classifier\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.base_classifiers_ = [clf.fit(X, y) for clf in self.base_classifiers]\n",
    "        predictions = np.column_stack([clf.predict(X) for clf in self.base_classifiers_])\n",
    "        self.meta_classifier_ = self.meta_classifier.fit(predictions, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        base_predictions = np.column_stack([clf.predict(X) for clf in self.base_classifiers_])\n",
    "        return self.meta_classifier_.predict(base_predictions)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da2cf09496403592"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "base_classifiers = [LinearDiscriminantAnalysis_model, GaussianNB_model, QuadraticDiscriminantAnalysis_model, KNeighborsClassifier_model]\n",
    "meta_classifier = LogisticRegression_model\n",
    "\n",
    "stacking_clf_41 = StackingClassifier(base_classifiers, meta_classifier)\n",
    "stacking_clf_41.fit(X_train_data, y_train_data)\n",
    "y_pred_stacking_clf_41 = stacking_clf_41.predict(X_test_data)\n",
    "\n",
    "accuracy_stacking_clf_41 = accuracy_score(y_test_data, y_pred_stacking_clf_41)\n",
    "end_time = time.time()\n",
    "stacking_clf_41_time = end_time - start_time\n",
    "\n",
    "stacking_clf_41_precision, stacking_clf_41_recall, stacking_clf_41_f1_score = calculate_metrics(y_test_data, y_pred_stacking_clf_41)\n",
    "print(f'Dokładność Stacking Classifiera - meta LogisticRegression: {accuracy_stacking_clf_41:.2f}')\n",
    "print(f'Stacking Classifier - meta LogisticRegression, training time: {stacking_clf_41_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ee40f18624bb32c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "base_classifiers = [LinearDiscriminantAnalysis_model, GaussianNB_model, QuadraticDiscriminantAnalysis_model, LogisticRegression_model]\n",
    "meta_classifier = KNeighborsClassifier_model\n",
    "\n",
    "stacking_clf_42 = StackingClassifier(base_classifiers, meta_classifier)\n",
    "stacking_clf_42.fit(X_train_data, y_train_data)\n",
    "y_pred_stacking_clf_42 = stacking_clf_42.predict(X_test_data)\n",
    "\n",
    "accuracy_stacking_clf_42 = accuracy_score(y_test_data, y_pred_stacking_clf_42)\n",
    "end_time = time.time()\n",
    "stacking_clf_42_time = end_time - start_time\n",
    "\n",
    "stacking_clf_42_precision, stacking_clf_42_recall, stacking_clf_42_f1_score = calculate_metrics(y_test_data, y_pred_stacking_clf_42)\n",
    "print(f'Dokładność Stacking Classifiera - meta KNeighborsClassifier_model: {accuracy_stacking_clf_42:.2f}')\n",
    "print(f'Stacking Classifier - meta KNeighborsClassifier_model, training time: {stacking_clf_42_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35348369806cd4e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "base_classifiers = [LinearDiscriminantAnalysis_model, GaussianNB_model, KNeighborsClassifier_model, LogisticRegression_model]\n",
    "meta_classifier = QuadraticDiscriminantAnalysis_model\n",
    "\n",
    "stacking_clf_43 = StackingClassifier(base_classifiers, meta_classifier)\n",
    "stacking_clf_43.fit(X_train_data, y_train_data)\n",
    "y_pred_stacking_clf_43 = stacking_clf_43.predict(X_test_data)\n",
    "\n",
    "accuracy_stacking_clf_43 = accuracy_score(y_test_data, y_pred_stacking_clf_43)\n",
    "end_time = time.time()\n",
    "stacking_clf_43_time = end_time - start_time\n",
    "\n",
    "stacking_clf_43_precision, stacking_clf_43_recall, stacking_clf_43_f1_score = calculate_metrics(y_test_data, y_pred_stacking_clf_43)\n",
    "print(f'Dokładność Stacking Classifiera - meta QuadraticDiscriminantAnalysis_model: {accuracy_stacking_clf_43:.2f}')\n",
    "print(f'Stacking Classifier - meta QuadraticDiscriminantAnalysis_model, training time: {stacking_clf_43_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6b947bf7efdc9b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "base_classifiers = [LinearDiscriminantAnalysis_model, QuadraticDiscriminantAnalysis_model, KNeighborsClassifier_model, LogisticRegression_model]\n",
    "meta_classifier = GaussianNB_model\n",
    "\n",
    "stacking_clf_44 = StackingClassifier(base_classifiers, meta_classifier)\n",
    "stacking_clf_44.fit(X_train_data, y_train_data)\n",
    "y_pred_stacking_clf_44 = stacking_clf_44.predict(X_test_data)\n",
    "\n",
    "accuracy_stacking_clf_44 = accuracy_score(y_test_data, y_pred_stacking_clf_44)\n",
    "end_time = time.time()\n",
    "stacking_clf_44_time = end_time - start_time\n",
    "\n",
    "stacking_clf_44_precision, stacking_clf_44_recall, stacking_clf_44_f1_score = calculate_metrics(y_test_data, y_pred_stacking_clf_44)\n",
    "print(f'Dokładność Stacking Classifiera - meta GaussianNB_model: {accuracy_stacking_clf_44:.2f}')\n",
    "print(f'Stacking Classifier - meta GaussianNB_model, training time: {stacking_clf_44_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2cbc5b9ab155ff0a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "base_classifiers = [GaussianNB_model, QuadraticDiscriminantAnalysis_model, KNeighborsClassifier_model, LogisticRegression_model]\n",
    "meta_classifier = LinearDiscriminantAnalysis_model\n",
    "\n",
    "stacking_clf_45 = StackingClassifier(base_classifiers, meta_classifier)\n",
    "stacking_clf_45.fit(X_train_data, y_train_data)\n",
    "y_pred_stacking_clf_45 = stacking_clf_45.predict(X_test_data)\n",
    "\n",
    "accuracy_stacking_clf_45 = accuracy_score(y_test_data, y_pred_stacking_clf_45)\n",
    "end_time = time.time()\n",
    "stacking_clf_45_time = end_time - start_time\n",
    "\n",
    "stacking_clf_45_precision, stacking_clf_45_recall, stacking_clf_45_f1_score = calculate_metrics(y_test_data, y_pred_stacking_clf_45)\n",
    "print(f'Dokładność Stacking Classifiera - meta LinearDiscriminantAnalysis_model: {accuracy_stacking_clf_45:.2f}')\n",
    "print(f'Stacking Classifier - meta LinearDiscriminantAnalysis_model, training time: {stacking_clf_45_time:.2f} seconds')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ba6b7a720de742d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d5c74509b8d80f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
